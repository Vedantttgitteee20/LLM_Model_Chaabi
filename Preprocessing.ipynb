{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846e0e53-54d3-43cd-9d28-c3d3d215a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinee\\miniconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9027186b-0586-4fac-8251-7f16ccfda1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bigBasketProducts.csv')\n",
    "data.head()\n",
    "data = data.drop('rating', axis=1)\n",
    "# Drop all rows with null values in a particular column\n",
    "column_with_nulls = 'description'\n",
    "data = data.dropna(subset=[column_with_nulls])\n",
    "data = data.dropna(subset=['brand'])\n",
    "data = data.dropna(subset=['product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a533c1f-3088-4bc9-b09e-1c0c25889a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(data['category'][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6268aa71-ebc8-4ad8-ab87-bcd1ad7373b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product:Garlic Oil - Vegetarian Capsule 500 mg|category:Beauty & Hygiene|sub_category:Hair Care|brand:Sri Sri Ayurveda |sale_price:220.0|market_price:220.0|type:Hair Oil & Serum|description:This Product contains Garlic Oil that is known to help proper digestion, maintain proper cholesterol levels, support cardiovascular and also build immunity.  For Beauty tips, tricks & more visit https://bigbasket.blog/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Concatenated'] = data.apply(lambda row: '|'.join([f'{col}:{val}' for col, val in row.items() if col != 'index']), axis=1)\n",
    "data['Concatenated'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b73fd9d-11b2-4011-baee-5fc4bd80f7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# You can replace this with the actual name of your DataFrame\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1654cdab-a64a-4333-9c76-a175017a50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 858/858 [27:40<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "sentences = data['Concatenated'].tolist()\n",
    "from tqdm import tqdm\n",
    "# Example function to process a batch\n",
    "def process_batch(batch):\n",
    "    # Replace this with your actual function logic\n",
    "    print(f\"Processing batch: {batch}\")\n",
    "\n",
    "# Split the list into batches of 100\n",
    "batch_size = 32\n",
    "batched_sentences = [sentences[i:i+batch_size] for i in range(0, len(sentences), batch_size)]\n",
    "embeddings = []\n",
    "# Iterate over batches and call the process_batch function\n",
    "for sentences in tqdm(batched_sentences):\n",
    "    # Tokenize input sentences\n",
    "    tokenized_input = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    # Move the input tensors to GPU\n",
    "    tokenized_input = {key: value.to(device) for key, value in tokenized_input.items()}\n",
    "\n",
    "    # Forward pass through BERT model\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized_input)\n",
    "    del(tokenized_input)\n",
    "    # Extract embeddings from the output\n",
    "    embedding = output.last_hidden_state.mean(dim=1)  # Using mean pooling to get sentence embeddings\n",
    "    embeddings.append(embedding.cpu().detach())\n",
    "    del(embedding)\n",
    "# print(sentence_embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288b5fee-5687-4e7b-99a2-c6f6c947d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tensor = torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda17ade-c144-43a7-8488-7c7f4bc674ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27439, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "757dda7b-b291-4b67-9783-c9c15f0e45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings,'embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4e6c5b-3bd8-4dae-b4af-eaf35b789ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f8e9a3a-6c3b-47e8-9fb1-58708c8be001",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73885331-a569-47f6-af0a-a5141fc009cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone      \n",
    "\n",
    "# pinecone.init(      \n",
    "# \tapi_key='ec5d5e0d-f392-4654-ad4c-d030f2f8adc7',      \n",
    "# \tenvironment='us-east1-gcp'      \n",
    "# )      \n",
    "# index = pinecone.Index('bigbasket')\n",
    "\n",
    "import pinecone      \n",
    "\n",
    "pinecone.init(      \n",
    "\tapi_key='1b7c40a9-2a02-4f0c-b096-2e5d34ce2366',      \n",
    "\tenvironment='gcp-starter'      \n",
    ")      \n",
    "index = pinecone.Index('bigbasket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecca23b8-830f-4f03-b4e0-2e436a52914a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63ab205c-7951-49f6-8d75-4ae9478b1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = []\n",
    "for i in range(len(embeddings)):\n",
    "    e = embeddings[i].tolist()\n",
    "    id = str(i)\n",
    "    tup = (id,e)\n",
    "    upload.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d37ca-a51d-4497-a2e9-8bcf59cce208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▎                                                                    | 42/275 [01:51<10:22,  2.67s/it]"
     ]
    }
   ],
   "source": [
    "# Alternatively, upload vectors in batches\n",
    "batch_size = 100\n",
    "for i in tqdm(range(0, len(upload), batch_size)):\n",
    "    batch_vectors = upload[i:i + batch_size]\n",
    "    response = index.upsert(batch_vectors)\n",
    "    # print(f\"Inserted batch with IDs {batch_ids[0]} to {batch_ids[-1]}, Pinecone response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2c35f-3729-43a6-8e04-90af63b8d4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
